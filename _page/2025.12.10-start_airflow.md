---
title: [Airflow] 01-Airflow 살펴보기
categories: [MLOps, Orchestration]
tags: [MLOps, Orchestration, Airflow, Data Pipeline, DAG]
---

# Airflow 살펴보기

복잡한 데이터 작업의 의존성을 해결하는 **DAG(Directed Acyclic Graph)**의 핵심 원리와 이를 구현한 워크플로우 관리 도구 **Airflow**의 아키텍처, 그리고 배치 처리에 특화된 장단점을 파악하여 효율적인 데이터 파이프라인 구축 전략을 제시한다.

## 데이터 파이프라인

**데이터 파이프라인**은 데이터를 목적에 맞게 처리하기 위해 실행되는 일련의 태스크(Task) 집합이다. 각 태스크는 독립적으로 존재하지만, 실제 업무에서는 "A 작업이 끝나야 B 작업을 시작할 수 있다"는 식의 **의존성(Dependency)**을 가지는 경우가 대부분이다.

이러한 의존성을 시각적으로 표현하고 관리하기 위해 파이프라인을 그래프 형태로 모델링한다. 

그래프 내에 순환(Cycle)이 발생하면 작업 A가 B를 기다리고, B가 다시 A를 기다리는 **교착 상태(Deadlock)**에 빠질 수 있다. 따라서 데이터 파이프라인은 반드시 **방향성(Directed)**을 가지며 순환하지 않는(Acyclic) 구조여야 한다. 이를 위해 **DAG(Directed Acyclic Graph, 방향성 비순환 그래프)**를 사용한다.

DAG는 다음과 같은 단순한 알고리즘을 통해 파이프라인을 실행할 수 있다.
1. 의존성 검사 : 모든 태스크를 스캔하며, 선행 작업이 완료되었는지 확인한다.
2. 실행 대기 : 선행 작업이 모두 완료된 태스크를 실행 대기열(Queue)에 추가한다.
3. 실행 및 완료 : Worker가 대기열의 태스크를 가져와 실행하고, 완료 시 생태를 업데이트한다.
4. 반복 : 그래프 내 모든 태스크가 완료될 때까지 위 과정을 반복한다.

이러한 DAG 실행 알고리즘을 적용하면 다음과 같은 이점을 얻을 수 있다.
- 태스크를 병렬로 실행하여 가용 컴퓨팅 리소스를 효율적으로 활용
- 파이프라인을 작은 점진적인 태스크로 명확히 분리 가능
- 실패한 태스크에 대해서만 재실행이 가능하여 효율적으로 구성 가능

## Airflow

**Airflow**는 이러한 DAG 구조를 코드로 정의하고, 스케줄링 및 모니터링을 수행하는 플랫폼이다. Python 코드로 작성된 DAG File을 통해 태스크의 집합과 의존성을 명확하게 기술한다.

Airflow는 다음 3가지 핵심 컴포넌트로 동작한다. 
- **Scheduler** : DAG를 분석하고, 현재 시점에서 DAG 스케줄이 지난 경우 DAG Task를 예약
- **Worker** : Scheduler가 예약한 Task를 선택하고 실행
- **Web Server** : Scheduler가 분석한 DAG를 시각화하고, DAG 실행과 결과에 대한 인터페이스 제공

Airflow를 사용하면 다음과 같은 이점을 얻을 수 있다.
- 유연한 확장성 : 다양한 라이브러리 및 외부 서비스와 쉽게 연동 가능
- 정교한 제어 : 특정 태스크만 부분적으로 재실행하거나, 과거 날짜의 데이터를 다시 처리하는 Backfill 기능
- 가시성 확보 : 웹 인터페이스를 통해 파이프라인의 병목 구간이나 실패 원인을 직관적으로 모델링 가능

Airflow는 다음과 같은 경우 적합하지 않다.
- 실시간 처리 스트리밍 : 배치 처리에 특화되어 있어, 초 단위 이하의 지연 시간을 요구하는 스트리밍 작업에는 부적합
- 잦은 구조 변경 : 실행 도중에 파이프라인의 구조가 수시로 바뀌는 동적 파이프라인을 구성하기에는 구조적 제약이 있다.
